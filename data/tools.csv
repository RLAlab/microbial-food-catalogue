"Broad scope","Name","Algorithm","Datasets","Reference","Link"
"Taste compound prediction","VirtuousMulti Taste","Random Forest with multi-objective evolutionary optimization","Trained on 360 compounds per class; tested on a larger external datasets, including: FooDB, FlavorDB, PhenolExplorer, Natural Product Atlas, PhytoHub","Androutsos et al. (2024)","https://virtuous.insybio.com/"
"Protein digestibility prediction","//","Transformer protein language model with SHAP for feature selection","Trained on 189 food items with 1671 features (nutritional data, amino acid composition, protein sequences); tested on 7 food items from diverse sources","Malvar et al. (2022)","https://www.microsoft.com/en-us/research/wp-content/uploads/2022/11/Researcher_Protein_Sara.pdf"
"Protein engineering","Pro-PRIME","Protein language model","Optimal growth temperatures from 96 million host bacterial strains + thermostability data from creatinase (18 single‐point mutants, 22 double‐point mutants, 21  triple‐point mutants, and 12 quadruple‐point mutants) for fine-tuning ","Bian et al. (2024)","https://github.com/ai4protein/Pro-Prime"
"Protein engineering","ESM-2","Transformer protein language model","Trained on 250 million protein sequences from UniRef50","Lin et al. (2023)","https://github.com/facebookresearch/esm"
"Protein engineering","Evo","Long-context transformer model","Trained on the OpenGenome dataset (80,000 bacterial and archaeal genomes and millions of predicted phage and plasmid sequences)","Nguyen et al. (2024)","https://github.com/evo-design/evo"
"Protein engineering","EvoProtGrad","Gradient-based discrete MCMC","Utilizes pretrained protein language models; tested on various fitness landscapes. ","Emami et al. (2023)","https://pemami4911.github.io/blog/2023/01/05/ppde.html"
"Protein engineering","AlphaMissense","Deep learning model","Fine-tuned on human and primate variant frequency databases, including ClinVar, to predict the pathogenicity of missense variants .","Cheng et al. (2023)","https://alphafold.ebi.ac.uk/"
"Protein engineering","AlphaFold","Deep neural network","Trained on protein structures from the Protein Data Bank (PDB) and multiple sequence alignments. The AlphaFold Protein Structure Database contains over 200 million predicted structures .","Jumper et al. (2021)","https://alphafold.ebi.ac.uk/"
"Protein engineering","AlphaFold3","Diffusion-based deep learning model","Trained on biomolecular complexes, including proteins, nucleic acids, and small molecules from Protein Data Bank (PDB).","Abramson et al. (2024)","https://alphafold.google/server/"
"Protein engineering","ESMFold","Transformer-based model","Trained on 250 million protein sequences from UniRef50","Lin et al. (2023)","https://github.com/facebookresearch/esm"
"Protein engineering","RoseTTAFold","Three-track neural network","Trained on protein structures from the Protein Data Bank (PDB) and multiple sequence alignments. Evaluated on 69 medium and hard targets in the CAMEO benchmark .","Baek et al. (2021)","https://github.com/baker-laboratory/RoseTTAFold"
"Protein engineering","RFDiffusion","Diffusion generative model","Fine-tuned on protein structure denoising tasks using the RoseTTAFold architecture.","Watson et al. (2023)","https://github.com/baker-laboratory/RFdiffusion"
"Protein engineering","ProteinMPNN","Deep neural network","Trained on protein structures from the Protein Data Bank as of August 2021, focusing on sequence optimization.","Dauparas et al. (2022)","https://github.com/dauparas/ProteinMPNN"
"Protein engineering","LigandMPNN","Deep neural network","Trained on protein-ligand complexes from the PDB as of December 2022, modeling non-protein components explicitly .","Dauparas et al. (2025)","https://github.com/dauparas/LigandMPNN"
"Protein engineering","ThermoMPNN","Deep neural network","Trained on a mega-scale dataset of over 200,000 data points to predict stability changes upon mutations .","Dieckhaus et al. (2024)","https://github.com/Kuhlman-Lab/ThermoMPNN"
"Template-free retrobiosynthesis","BioNavi-NP","Transformer neural network","33710 biochemical reactions from MetaCyc and KEGG + 60k natural product-like organic reactions from USPTO db. Test set (internal): 368 target molecules with complete biosynthetic pathways + test set (external): 25 unseen natural products","Zheng et al. (2022)","https://github.com/prokia/BioNavi-NP"
"Template-free retrobiosynthesis","//","Transformer neural network + transfer learning","1M organic chemical reactions from USPTO db + 56579 curated enzymatic reactions from ECREACT db.","Probst et al. (2022)","https://github.com/dsprobst/retrosynthesis"
"Metabolic engineering and modeling ","ARCTICA","Logistic regression + L1 regularisation (LASSO)","100k sample points per virtual phenotype (low- and high-producing Synechocystis sp. PCC 6803 strains) per each bioproduct (lauric acid, squalene, L-leucine, biomass) using Monte Carlo flux sampling.","Kugler et al.(2024)","https://doi.org/10.1016/j.ymben.2024.01.006"
"Metabolic engineering and modeling ","AMN (Artificial Metabolic Network)","Hybrid neural-mechanistic model (ANN + FBA surrogate solvers: Wt, LP, QP)","FBA-simulated datasets (~1000 samples on E. coli core and iML1515 models); experimental datasets: 110 growth rates (E. coli), 17,400 growth rates (E. coli KOs), 296 growth assays (P. putida)","Faure et al. (2023)","https://github.com/brsynth/amn"
"Metabolic engineering and modeling ","ART","Bayesian ensemble model","Simulated data (16 instances) and experimental datasets—including proteomics and production levels from 27 limonene strains, 50 beer-flavor strains, and 116 dodecanol replicates across 33 strains","Radivojević et al. (2020)","https://art.jbei.org/"
"Metabolic engineering and modeling ","MiYA","ANN ensemble","Experimental datasets from S. cerevisiae engineered for β-carotene (24 strains with promoter combinations and titers) and violacein (24 pre-screened strains with promoter combinations, titers, and purity metrics)","Zhou et al. (2018)","https://doi.org/10.1186/s12934-018-1033-9"
"Metabolic engineering and modeling ","REKINDLE","Conditional Generative Adversarial Network (GAN)","72,000 unique combinations of 411 kinetic parameters from E. coli metabolism, generated using the ORACLE framework","Choudhury et al. ","https://doi.org/10.1021/acs.jcim.0c01170"
"Downstream processing","Generative Flowsheet Transformer","Transformer-based language model","Trained on synthetic (8,000+) and real flowsheets (223)","Vogel et al. 2023","https://doi.org/10.1016/j.compchemeng.2023.108162"
